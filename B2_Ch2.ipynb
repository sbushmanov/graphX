{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5f2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.rdd._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.graphx._\n",
    "import scala.sys.process._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3b07e",
   "metadata": {},
   "source": [
    "# Create Graphs\n",
    "\n",
    "```\n",
    "def Graph.apply[VD, ED](\n",
    "    vertices: RDD[(VertexId, VD)],\n",
    "    edges: RDD[Edge[ED]],\n",
    "    defaultVertexAttr: VD = null)\n",
    ": Graph[VD, ED]\n",
    "\n",
    "def Graph.fromEdges[VD, ED](\n",
    "    edges: RDD[Edge[ED]],\n",
    "    defaultValue: VD)\n",
    ": Graph[VD, ED]\n",
    "\n",
    "def Graph.fromEdgeTuples[VD](\n",
    "    rawEdges: RDD[(VertexId, VertexId)],\n",
    "    defaultValue: VD,\n",
    "    uniqueEdges: Option[PartitionStrategy] = None)\n",
    ": Graph[VD, Int]\n",
    "\n",
    "def GraphLoader.edgeListFile(\n",
    "    sc: SparkContext,\n",
    "    path: String,\n",
    "    canonicalOrientation: Boolean = false,\n",
    "    minEdgePartitions: Int = 1)\n",
    ": Graph[Int, Int]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb171e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arr = List((1,2), (2,3), (5,6), (6,7))\n",
       "edges = ParallelCollectionRDD[0] at parallelize at <console>:38\n",
       "graph = org.apache.spark.graphx.impl.GraphImpl@3e4e5bc8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@3e4e5bc8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val arr = Seq((1,2), (2,3), (5,6), (6,7)).map{case Tuple2(x,y)=>(x.toLong, y.toLong)}\n",
    "val edges: RDD[(VertexId, VertexId)] = sc.parallelize(arr)\n",
    "val graph = Graph.fromEdgeTuples(edges, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b820428c",
   "metadata": {},
   "source": [
    "# Enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9702a60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warning: one feature warning; for details, enable `:setting -feature' or `:replay -feature'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Directed graph (each unordered pair of nodes is saved once): Email-Enron.txt \r\n",
      "# Enron email network (edge indicated that email was exchanged, undirected edges)\r\n",
      "# Nodes: 36692 Edges: 367662\r\n",
      "# FromNodeId\tToNodeId\r\n",
      "0\t1\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"head -n5 data/emailEnron.txt\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1c1148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path = file:///home/sergey/Spark_GraphX/data/emailEnron.txt\n",
       "emailGraph = org.apache.spark.graphx.impl.GraphImpl@5d2f9d38\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@5d2f9d38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = \"file:///home/sergey/Spark_GraphX/data/emailEnron.txt\"\n",
    "val emailGraph = GraphLoader.edgeListFile(sc, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcde97d",
   "metadata": {},
   "source": [
    "# Bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edba561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scala.io.Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc961c4",
   "metadata": {},
   "source": [
    "## Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f4b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# id\tingredient name\tcategory\n",
      "0\tmagnolia_tripetala\tflower\n",
      "1\tcalyptranthes_parriculata\tplant\n",
      "2\tchamaecyparis_pisifera_oil\tplant derivative\n",
      "3\tmackerel\tfish/seafood\n"
     ]
    }
   ],
   "source": [
    "Source.\n",
    "    fromFile(\"./data/ingr_info.tsv\").\n",
    "    getLines.\n",
    "    take(5).\n",
    "    foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8ebc2",
   "metadata": {},
   "source": [
    "## Compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fcabbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# id\tCompound name\tCAS number\n",
      "0\tjasmone\t488-10-8\n",
      "1\t5-methylhexanoic_acid\t628-46-6\n",
      "2\tl-glutamine\t56-85-9\n",
      "3\t1-methyl-3-methoxy-4-isopropylbenzene\t1076-56-8\n"
     ]
    }
   ],
   "source": [
    "Source.\n",
    "    fromFile(\"./data/comp_info.tsv\").\n",
    "    getLines().\n",
    "    take(5).\n",
    "    foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3613791",
   "metadata": {},
   "source": [
    "## Adjacency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9cdc87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ingredient id\tcompound id\n",
      "1392\t906\n",
      "1259\t861\n",
      "1079\t673\n",
      "22\t906\n"
     ]
    }
   ],
   "source": [
    "Source.\n",
    "    fromFile(\"./data/ingr_comp.tsv\").\n",
    "    getLines().\n",
    "    take(5).\n",
    "    foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c70460",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55771b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined trait FNNode\n",
       "defined class Ingredient\n",
       "defined class Compound\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// https://stackoverflow.com/questions/12705309/scala-case-class-inheritance\n",
    "sealed trait FNNode {\n",
    "    def name: String\n",
    "}\n",
    "case class Ingredient(name: String, category: String) extends FNNode\n",
    "case class Compound(name: String, cas: String) extends FNNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff3a06b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Syntax Error.",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "// class FNNode(val name: String) extends Serializable\n",
    "// case class Ingredient(override val name: String, category: String) extends FNNode(name)\n",
    "// case class Compound(override val name: String, cas: String) extends FNNode(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d1dcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ingsPath = file:///home/sergey/Spark_GraphX/data/ingr_info.tsv\n",
       "ingredients = MapPartitionsRDD[25] at map at <console>:47\n",
       "compsPath = file:///home/sergey/Spark_GraphX/data/comp_info.tsv\n",
       "comps = MapPartitionsRDD[29] at map at <console>:56\n",
       "linksPath = file:///home/sergey/Spark_GraphX/data/ingr_comp.tsv\n",
       "links = MapPartitionsRDD[33] at map at <console>:65\n",
       "nodes = UnionRDD[34] at $plus$plus at <console>:70\n",
       "foodNetwork = org.apache.spark.graphx.impl.GraphImpl@3b...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@3b..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ingsPath = \"file:///home/sergey/Spark_GraphX/data/ingr_info.tsv\"\n",
    "val ingredients: RDD[(VertexId, FNNode)] =\n",
    "    sc.textFile(ingsPath).\n",
    "    filter(! _.startsWith(\"#\")).\n",
    "    map {line =>\n",
    "            val row = line.split(\"\\\\s+\")\n",
    "            (row(0).toLong, Ingredient(row(1), row(2)))\n",
    "}\n",
    "\n",
    "val compsPath = \"file:///home/sergey/Spark_GraphX/data/comp_info.tsv\"\n",
    "val comps: RDD[(VertexId, FNNode)] =\n",
    "    sc.textFile(compsPath).\n",
    "    filter(! _.startsWith(\"#\")).\n",
    "    map {line =>\n",
    "            val row = line.split(\"\\\\s+\")\n",
    "            (10000L + row(0).toLong, Compound(row(1), row(2)))\n",
    "}\n",
    "\n",
    "val linksPath = \"file:///home/sergey/Spark_GraphX/data/ingr_comp.tsv\"\n",
    "val links: RDD[Edge[Int]] =\n",
    "    sc.textFile(linksPath).\n",
    "    filter(! _.startsWith(\"#\")).\n",
    "    map {line => \n",
    "            val row = line split '\\t'\n",
    "            Edge(row(0).toLong, 10000L + row(1).toLong, 1)\n",
    "}\n",
    "\n",
    "val nodes = ingredients ++ comps\n",
    "\n",
    "val foodNetwork = Graph(nodes, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbc52f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "showTriplet: (t: org.apache.spark.graphx.EdgeTriplet[FNNode,Int])String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ingredient calyptranthes_parriculata contains citral_(neral)\n",
      "The ingredient chamaecyparis_pisifera_oil contains undecanoic_acid\n",
      "The ingredient hyssop contains myrtenyl_acetate\n",
      "The ingredient hyssop contains 4-(2,6,6-trimethyl-cyclohexa-1,3-dienyl)but-2-en-4-one\n",
      "The ingredient buchu contains menthol\n"
     ]
    }
   ],
   "source": [
    "def showTriplet(t: EdgeTriplet[FNNode,Int]): String = \n",
    "    \"The ingredient \" ++ t.srcAttr.name ++ \" contains \" ++ t.dstAttr.name\n",
    "\n",
    "foodNetwork.\n",
    "    triplets.\n",
    "    take(5).\n",
    "    foreach(t => println(showTriplet(t) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916894ce",
   "metadata": {},
   "source": [
    "# Social Ego Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada8ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached version of breeze_2.13-2.1.0.jar\n",
      "Using cached version of breeze_2.13-2.1.0.jar\n"
     ]
    }
   ],
   "source": [
    "%addjar breeze_2.13-2.1.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2457e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined type alias Feature\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scala.math.abs\n",
    "import breeze.linalg.SparseVector\n",
    "import scala.io.Source\n",
    "\n",
    "type Feature = breeze.linalg.SparseVector[Int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7838c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114985346359714431656 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "featPath = file:///home/sergey/Spark_GraphX/data/ego.feat\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "file:///home/sergey/Spark_GraphX/data/ego.feat"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featPath = \"file:///home/sergey/Spark_GraphX/data/ego.feat\"\n",
    "Source.fromURL(featPath).getLines.take(1).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f9895bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365547835"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"114985346359714431656\".hashCode.toLong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "224b8a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureMap = Map(421252149 -> SparseVector(1319)((0,0), (1,1), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0), (14,0), (15,0), (16,0), (17,0), (18,0), (19,0), (20,0), (21,0), (22,0), (23,0), (24,0), (25,0), (26,0), (27,0), (28,0), (29,0), (30,0), (31,0), (32,0), (33,0), (34,0), (35,0), (36,0), (37,0), (38,0), (39,0), (40,0), (41,0), (42,0), (43,0), (44,0), (45,0), (46,0), (47,0), (48,0), (49,0), (50,0), (51,0), (52,0), (53,0), (54,0), (55,0), (56,0), (57,0), (58,0), (59,0), (60,0), (61,0), (62,0), (63,0), (64,0), (65,0), (66,0), (67,0), (68,0), (69,0), (70,0), (71,0), (72,0), (73,0), (74,0), (75,0), (76,0), (77,0), (78,0), (79,0), (80,0), (81,0), (82,0), (83,0), (84,0), (85,0), (86,0), (87,0), (88,0), (89,0), (90,0), (91,0), (92...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(421252149 -> SparseVector(1319)((0,0), (1,1), (2,0), (3,0), (4,0), (5,0), (6,0), (7,0), (8,0), (9,0), (10,0), (11,0), (12,0), (13,0), (14,0), (15,0), (16,0), (17,0), (18,0), (19,0), (20,0), (21,0), (22,0), (23,0), (24,0), (25,0), (26,0), (27,0), (28,0), (29,0), (30,0), (31,0), (32,0), (33,0), (34,0), (35,0), (36,0), (37,0), (38,0), (39,0), (40,0), (41,0), (42,0), (43,0), (44,0), (45,0), (46,0), (47,0), (48,0), (49,0), (50,0), (51,0), (52,0), (53,0), (54,0), (55,0), (56,0), (57,0), (58,0), (59,0), (60,0), (61,0), (62,0), (63,0), (64,0), (65,0), (66,0), (67,0), (68,0), (69,0), (70,0), (71,0), (72,0), (73,0), (74,0), (75,0), (76,0), (77,0), (78,0), (79,0), (80,0), (81,0), (82,0), (83,0), (84,0), (85,0), (86,0), (87,0), (88,0), (89,0), (90,0), (91,0), (92..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureMap: Map[Long, Feature] =\n",
    "    Source.\n",
    "    fromURL(featPath).\n",
    "    getLines().\n",
    "    map{line =>\n",
    "        val row = line.split(\"\\\\s+\")\n",
    "        val key = abs(row.head.hashCode.toLong)\n",
    "        val feat = SparseVector(row.tail.map(_.toInt))\n",
    "        (key, feat)\n",
    "}.toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d50bd6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edgesPath = file:///home/sergey/Spark_GraphX/data/ego.edges\n",
       "edges = MapPartitionsRDD[5] at map at <console>:151\n",
       "egoNetwork = org.apache.spark.graphx.impl.GraphImpl@5464a884\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@5464a884"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val edgesPath = \"file:///home/sergey/Spark_GraphX/data/ego.edges\"\n",
    "\n",
    "val edges: RDD[Edge[Int]] =\n",
    "    sc.textFile(edgesPath).\n",
    "    map {line =>\n",
    "            val row = line.split(\"\\\\s+\")\n",
    "            val srcId = abs(row(0).hashCode.toLong)\n",
    "            val dstId = abs(row(1).hashCode.toLong)\n",
    "            val srcFeat = featureMap(srcId)\n",
    "            val dstFeat = featureMap(dstId)\n",
    "            val numCommonFeats = srcFeat.dot(dstFeat)\n",
    "            Edge(srcId, dstId, numCommonFeats)\n",
    "}\n",
    "\n",
    "val egoNetwork: Graph[Int,Int] = Graph.fromEdges(edges, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c41943ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1852"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egoNetwork.edges.filter(_.attr == 3).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
